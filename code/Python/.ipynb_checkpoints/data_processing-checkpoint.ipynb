{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e033c608-00b7-4287-ba0e-beafc35b3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re # For more robust number extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237a8bfa-17f4-4949-98c5-9f5723f9d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_log_files(data_folder_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads all LOG_*.TXT files from the specified folder, sorts them numerically,\n",
    "    and combines them into a single Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data_folder_path (str): The path to the folder containing the .txt log files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing all combined data, or an empty\n",
    "                      DataFrame if no suitable files are found or an error occurs.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(data_folder_path):\n",
    "        print(f\"Error: Folder '{data_folder_path}' not found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Pattern to match LOG_ followed by numbers and .TXT extension (case-insensitive for .TXT)\n",
    "    file_pattern = os.path.join(data_folder_path, \"LOG_*.TXT\")\n",
    "    \n",
    "    # Using glob to find all matching files\n",
    "    # We need to be careful with case sensitivity on different OS for the extension\n",
    "    # So we list all .txt files and then filter\n",
    "    all_files_in_folder = glob.glob(os.path.join(data_folder_path, \"*\"))\n",
    "    \n",
    "    txt_files = []\n",
    "    for f_path in all_files_in_folder:\n",
    "        filename = os.path.basename(f_path)\n",
    "        if filename.upper().startswith(\"LOG_\") and filename.upper().endswith(\".TXT\"):\n",
    "            txt_files.append(f_path)\n",
    "\n",
    "    if not txt_files:\n",
    "        print(f\"No LOG_*.TXT files found in '{data_folder_path}'.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Sort files based on the number in their name (e.g., LOG_1.TXT, LOG_2.TXT, LOG_10.TXT)\n",
    "    def sort_key(filepath):\n",
    "        filename = os.path.basename(filepath)\n",
    "        # Extract number using regex: looks for LOG_ followed by one or more digits\n",
    "        match = re.search(r'LOG_(\\d+)\\.TXT', filename, re.IGNORECASE)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        # If pattern doesn't match, put it at the end (or handle as error)\n",
    "        return float('inf') \n",
    "\n",
    "    sorted_files = sorted(txt_files, key=sort_key)\n",
    "    \n",
    "    print(\"Files to be processed in order:\")\n",
    "    for f in sorted_files:\n",
    "        print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "    all_dataframes = []\n",
    "    for file_path in sorted_files:\n",
    "        try:\n",
    "            # Assuming the first line is always the header\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Optional: Add a column to indicate the source file\n",
    "            # df['source_file'] = os.path.basename(file_path) \n",
    "            all_dataframes.append(df)\n",
    "            print(f\"Successfully read and processed: {os.path.basename(file_path)}\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: File {os.path.basename(file_path)} is empty and will be skipped.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {os.path.basename(file_path)}: {e}\")\n",
    "\n",
    "    if not all_dataframes:\n",
    "        print(\"No data could be read from the files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # The 'Log_Index' will restart for each file. \n",
    "    # 'ignore_index=True' above gives a new unique index to the combined DataFrame.\n",
    "    # The original 'Log_Index' column remains, showing its per-file sequence.\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044ab58d-55ae-45a5-954b-01496cb9af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to be processed in order:\n",
      "  - LOG_18.TXT\n",
      "  - LOG_19.TXT\n",
      "Successfully read and processed: LOG_18.TXT\n",
      "Successfully read and processed: LOG_19.TXT\n",
      "\n",
      "--- Combined DataFrame ---\n",
      "Shape: (37434, 23)\n",
      "\n",
      "Head:\n",
      "   Log_Index  CPU_TempC  BMP_TempC  BMP_PressPa  CO2_ppm  SCD30_TempC  \\\n",
      "0          0      34.42      25.24     99251.11        0        28.27   \n",
      "1          1      34.42      25.24     99251.11        0        28.27   \n",
      "2          2      35.10      25.24     99251.11      637        28.23   \n",
      "3          3      34.42      25.24     99251.11      637        28.23   \n",
      "4          4      34.42      25.24     99251.12      724        28.20   \n",
      "\n",
      "   SCD30_Hum_%  SHT_TempC  SHT_Hum_%  GPS_Lat  ...  GPS_Month  GPS_Day  \\\n",
      "0        33.64      25.29      28.25      0.0  ...          0        0   \n",
      "1        33.64      25.36      28.37      0.0  ...          0        0   \n",
      "2        33.36      25.43      28.47      0.0  ...          0        0   \n",
      "3        33.36      25.45      28.50      0.0  ...          0        0   \n",
      "4        33.51      25.45      28.33      0.0  ...          0        0   \n",
      "\n",
      "   GPS_Hour  GPS_Min  GPS_Sec  GPS_MilliSec  GPS_Fix  BMP_Health  \\\n",
      "0         0        0        0             0        0           1   \n",
      "1         0        0        0             0        0           1   \n",
      "2         0        0        0             0        0           1   \n",
      "3         0        0        0             0        0           1   \n",
      "4         0        0        0             0        0           1   \n",
      "\n",
      "   SCD30_Health  SHT_Health  \n",
      "0             1           1  \n",
      "1             1           1  \n",
      "2             1           1  \n",
      "3             1           1  \n",
      "4             1           1  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Tail:\n",
      "       Log_Index  CPU_TempC  BMP_TempC  BMP_PressPa  CO2_ppm  SCD30_TempC  \\\n",
      "37429      17801      35.10      26.35     99648.94      634        27.33   \n",
      "37430      17802      35.10      26.35     99648.94      635        27.32   \n",
      "37431      17803      35.10      26.35     99648.95      635        27.32   \n",
      "37432      17804      35.10      26.35     99648.97      634        27.34   \n",
      "37433      17805      35.77      26.35     99648.98      634        27.34   \n",
      "\n",
      "       SCD30_Hum_%  SHT_TempC  SHT_Hum_%  GPS_Lat  ...  GPS_Month  GPS_Day  \\\n",
      "37429        27.61      25.42      20.24      0.0  ...          0        0   \n",
      "37430        27.65      25.43      20.28      0.0  ...          0        0   \n",
      "37431        27.65      25.43      20.34      0.0  ...          0        0   \n",
      "37432        27.65      25.45      20.34      0.0  ...          0        0   \n",
      "37433        27.65      25.47      20.29      0.0  ...          0        0   \n",
      "\n",
      "       GPS_Hour  GPS_Min  GPS_Sec  GPS_MilliSec  GPS_Fix  BMP_Health  \\\n",
      "37429         0        0        0             0        0           1   \n",
      "37430         0        0        0             0        0           1   \n",
      "37431         0        0        0             0        0           1   \n",
      "37432         0        0        0             0        0           1   \n",
      "37433         0        0        0             0        0           1   \n",
      "\n",
      "       SCD30_Health  SHT_Health  \n",
      "37429             1           1  \n",
      "37430             1           1  \n",
      "37431             1           1  \n",
      "37432             1           1  \n",
      "37433             1           1  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37434 entries, 0 to 37433\n",
      "Data columns (total 23 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Log_Index     37434 non-null  int64  \n",
      " 1   CPU_TempC     37434 non-null  float64\n",
      " 2   BMP_TempC     37434 non-null  float64\n",
      " 3   BMP_PressPa   37434 non-null  float64\n",
      " 4   CO2_ppm       37434 non-null  int64  \n",
      " 5   SCD30_TempC   37434 non-null  float64\n",
      " 6   SCD30_Hum_%   37434 non-null  float64\n",
      " 7   SHT_TempC     37434 non-null  float64\n",
      " 8   SHT_Hum_%     37434 non-null  float64\n",
      " 9   GPS_Lat       37434 non-null  float64\n",
      " 10  GPS_Lon       37434 non-null  float64\n",
      " 11  GPS_Alt_m     37434 non-null  float64\n",
      " 12  GPS_Year      37434 non-null  int64  \n",
      " 13  GPS_Month     37434 non-null  int64  \n",
      " 14  GPS_Day       37434 non-null  int64  \n",
      " 15  GPS_Hour      37434 non-null  int64  \n",
      " 16  GPS_Min       37434 non-null  int64  \n",
      " 17  GPS_Sec       37434 non-null  int64  \n",
      " 18  GPS_MilliSec  37434 non-null  int64  \n",
      " 19  GPS_Fix       37434 non-null  int64  \n",
      " 20  BMP_Health    37434 non-null  int64  \n",
      " 21  SCD30_Health  37434 non-null  int64  \n",
      " 22  SHT_Health    37434 non-null  int64  \n",
      "dtypes: float64(10), int64(13)\n",
      "memory usage: 6.6 MB\n"
     ]
    }
   ],
   "source": [
    "    input_folder = \"Data_In\" \n",
    "    \n",
    "    combined_data = combine_log_files(input_folder)\n",
    "\n",
    "    if not combined_data.empty:\n",
    "        print(\"\\n--- Combined DataFrame ---\")\n",
    "        print(\"Shape:\", combined_data.shape)\n",
    "        print(\"\\nHead:\")\n",
    "        print(combined_data.head())\n",
    "        print(\"\\nTail:\")\n",
    "        print(combined_data.tail())\n",
    "        print(\"\\nInfo:\")\n",
    "        combined_data.info()\n",
    "\n",
    "        # Optional: Save the combined data to a new CSV file\n",
    "        # output_csv_path = \"combined_logs.csv\"\n",
    "        # combined_data.to_csv(output_csv_path, index=False)\n",
    "        # print(f\"\\nCombined data saved to {output_csv_path}\")\n",
    "    else:\n",
    "        print(\"No data was combined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d64793-7f6d-4360-b6ba-bbd7458d3602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
